"""* Copyright (c) 2009, Jeffrey Tchang* Copyright (c) 2021, Rutger Lubbers (ilionx)** All rights reserved.*** THIS SOFTWARE IS PROVIDED ''AS IS'' AND ANY* EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY* DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES* (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;* LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND* ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT* (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS* SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."""import getoptimport loggingimport sysfrom ldif import LDIFParser"""Known IssuesThe python ldif.py module does not like distinguished names that havean unescaped comma. Example would be:dn: cn=Bill, Kim and Family,mail=abc@example.comTo fix this, the comma needs to be escaped with a backslash like so:dn: cn=Bill\, Kim and Family,mail=abc@example.com"""# The main issue with turning an LDIF into a CSV are multivalued attributes# The first problem is figuring out if an attribute is multivalued. If it is, you have# no way of knowing how many values it may have. This poses a problem as with CSVs you# can only have a single column.# My solution to this is to parse through the entire LDIF file twice. The first pass# figures out how many columns you will need to ensure a full extraction of the data.# The second pass actually outputs the CSV. Obviously this is 2*O(n).# One of the issues with this is that a lot of spreadsheet programs will only support# a maximum number of columns. Suppose a multivalued attribute had 200 or so values.# This would eat up 200 columns. OpenOffice's maximum number of columns is 1024.# A handler that simply throws away any logging messages sent to itclass NullHandler(logging.Handler):    def emit(self, record):        pass# This class handles reading the attributes and storing them into a list. It is used# for the first pass of the LDIF fileclass LDIFAttributeParser(LDIFParser):    attribute_dictionary = dict()    def __init__(self, input_file):        LDIFParser.__init__(self, input_file)        self.attribute_dictionary = dict()    # This function is called whenever an entry is parsed out    def handle(self, dn, entry):        # Always add the dn attribute with cardinality 1        self.attribute_dictionary["dn"] = 1        # Loop through each of the attribute names        for attribute_name in entry.keys():            # Add the name to the dictionary if it is not already there. Set the value to the cardinality of the            # of the attribute (the number of values that the attribute has)            if attribute_name not in self.attribute_dictionary:                self.attribute_dictionary[attribute_name] = len(entry[attribute_name])            # If the attribute name is already in the dictionary, update the cardinality if it is bigger than the            # one I can currently have stored            else:                if len(entry[attribute_name]) > self.attribute_dictionary[attribute_name]:                    self.attribute_dictionary[attribute_name] = len(entry[attribute_name])class LDIFCSVParser(LDIFParser):    attribute_dictionary = dict()    attributeList = []    field_separator = ";"    multi_field_separator = ","    text_delimiter = "\""    defaultOutput = sys.stdout    def __init__(self, input_file, headers, output):        LDIFParser.__init__(self, input_file)        self.headers = headers        self.defaultOutput = output    # This function is called whenever an entry is parsed out    def handle(self, dn, entry):        # Loop through each of the attributes        for index, attribute_name in enumerate(self.headers, start=1):            if attribute_name in entry:                j = 0                merged_value = ""                while j < len(entry[attribute_name]):                    attribute_value = entry[attribute_name][j]                    if not (self.check_printable(attribute_value)):                        attribute_value = repr(attribute_value)                    if len(merged_value) > 0:                        merged_value = merged_value + self.multi_field_separator                    merged_value = merged_value + attribute_value                    j = j + 1                self.defaultOutput.write(                    self.text_delimiter + merged_value + self.text_delimiter)            # If the attribute name is dn, print the fully qualified distinguished name            elif attribute_name == "dn":                self.defaultOutput.write(                    self.text_delimiter + str(dn) + self.text_delimiter)            # If the attribute name is not in the entry print field_separator(s)            else:                self.defaultOutput.write(self.text_delimiter + self.text_delimiter)            if index < len(self.headers):                self.defaultOutput.write(self.field_separator)        # Print a newline        self.defaultOutput.write("\n")    @staticmethod    def check_printable(message):        for char in message:            if ord(char) > 126 or ord(char) < 32:                return False        return True# Parses an LDIF file to find out all the attribute names as well as how many of each kind of attribute# are in the file. Returns a dictionary of attributes and the maximum number of times that value appears.def parse_ldif_attributes(filename):    # Open the LDIF file for reading    ldif_file = open(filename, "rb")    logger.debug("Opened <%s> for reading" % filename)    # Create an instance of the attribute parser which will handle LDIF entries    attribute_parser = LDIFAttributeParser(ldif_file)    # Perform the actual parsing using the AttributeParser    # This first pass is only to obtain the attributes    logger.debug("Parsing <%s> for attributes" % filename)    attribute_parser.parse()    # Close the file    ldif_file.close()    logger.debug("Closed file <%s>" % filename)    # Return the dictionary of attributes. The key is the attribute name. The value is the    # maximum number of times that value appears    return attribute_parser.attribute_dictionarydef generate_csv(filename,                 output,                 headers,                 field_separator=";",                 multi_field_separator=",",                 text_delimiter="\""):    # Open the LDIF file for reading    ldif_file = open(filename, "rb")    logger.debug("Opened <%s> for reading" % filename)    # Create an instance of the attribute parser which will handle LDIF entries    csv_parser = LDIFCSVParser(ldif_file, headers, output)    csv_parser.field_separator = field_separator    csv_parser.multi_field_separator = multi_field_separator    csv_parser.text_delimiter = text_delimiter    number_of_headers = len(headers)    for index, header_name in enumerate(headers, start=1):        output.write(text_delimiter + header_name + text_delimiter)        if index < number_of_headers:            output.write(field_separator)    # Write a newline after the header    output.write("\n")    # Print out the main CSV data    csv_parser.parse()    # Write a newline to end the file    output.write("\n")    # Close the file    ldif_file.close()def setup_logging(filename=""):    # Create the logger as a global variable    global logger    logger = logging.Logger("logger", logging.DEBUG)    # Create a handler to print to the log    if filename != "":        handler = logging.FileHandler(filename, "w")    else:        handler = NullHandler()    # Set how the handler will print the pretty log events    formatter = logging.Formatter("[%(asctime)s][%(funcName)s] - %(message)s",                                  '%m/%d/%y %I:%M%p')    handler.setFormatter(formatter)    # Append handler to the logger    logger.addHandler(handler)# Text to describe out this command is useddef usage():    usage = """  usage: python ldif2csv.py [options] <ldif_file>  -o <filename>   : File to write output. By default this is set to sys.stdout  -l <filename>   : File to write logging output. By default there is no logging.  -f <char>       : Character to separate the fields by. By default this is a                    semicolon. i.e. -f ";"  -m <char>       : Character to delimit the multi values text by. By default                     this is a comma. i.e. -m ","  -d <char>       : Character to delimit the text value by. By default this is a                    double quote. i.e. -d "\""  -H <char>       : List of comma separated field names."""    sys.stdout.write(usage)# Primary function calldef main():    # Setup logging to /dev/null in case no log file is specified    setup_logging()    # Variables to extract from command line (set the defaults here)    output_filename = ""    field_separator = ";"    multi_field_separator = ","    text_delimiter = "\""    headers = []    # Use getopt to get all the options that might be present    try:        option_value_list, remaining_items = getopt.getopt(sys.argv[1:], "o:l:f:d:m:H:")    except getopt.GetoptError as exceptionObject:        print(str(exceptionObject))        usage()        sys.exit(2)    if len(remaining_items) < 1:        print("Error: Expecting single filename argument at end of command line.\n")        usage()        sys.exit(2)    # Loop through each tuple returned    for option, value in option_value_list:        # Setup logging        if option == "-l":            setup_logging(value)            logger.debug("Logging initiated")        # Get output filename        if option == "-o":            output_filename = value        # Get field separator character        if option == "-f":            field_separator = value        # Get multi field separator character        if option == "-m":            multi_field_separator = value        # Get text delimiter character        if option == "-d":            text_delimiter = value        if option == "-H":            headers = value.split(",")    input_filename = remaining_items[0]    logger.debug("input_filename: %s" % input_filename)    logger.debug("output_filename: %s" % output_filename)    logger.debug("field_separator: %s" % field_separator)    logger.debug("multi_field_separator: %s" % multi_field_separator)    logger.debug("text_delimiter: %s" % text_delimiter)    if len(headers) == 0:        # First pass obtains the attributes inside the LDIF        attribute_dictionary = parse_ldif_attributes(input_filename)        logger.debug("Parsed attribute dictionary: " + repr(attribute_dictionary))        # Print out the CSV header sorted        headers = sorted(attribute_dictionary.keys())    # Default output is stdout    output = sys.stdout    if output_filename != "":        output = open(output_filename, "w")    # Second pass generates the actual CSV    generate_csv(input_filename,                 output,                 headers,                 field_separator,                 multi_field_separator,                 text_delimiter)    # Close the file    output.close()# Main entry point of programif __name__ == '__main__':    main()